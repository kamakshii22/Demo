{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3635cdbb",
      "metadata": {
        "id": "3635cdbb"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfe0594",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdfe0594",
        "outputId": "33fba6de-bd6b-4cd0-98ee-60cb3eafced8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "NeJKrCEoGPpI"
      },
      "id": "NeJKrCEoGPpI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "file = open(\"/content/frankenstein.txt\").read()"
      ],
      "metadata": {
        "id": "ZCBqKGuRHtyp"
      },
      "id": "ZCBqKGuRHtyp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "# standardization\n",
        "def tokenize_words(input):\n",
        "  input = input.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "processed_inputs = tokenize_words(file)"
      ],
      "metadata": {
        "id": "hTVYxjVJIiMg"
      },
      "id": "hTVYxjVJIiMg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chars to numbers\n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c,i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "54pY3MfrJI5L"
      },
      "id": "54pY3MfrJI5L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if words to chars or chars to num (?!) has worked?\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(\"Total numbers of characters:\", input_len)\n",
        "print(\"Total vocab:\", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzY-BdVsKqCI",
        "outputId": "28ff79e0-05fc-4ef8-a1f7-5491b9b013f3"
      },
      "id": "fzY-BdVsKqCI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total numbers of characters: 232972\n",
            "Total vocab: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seq length\n",
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "ReMfD5Y6LFpR"
      },
      "id": "ReMfD5Y6LFpR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through the sequence\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "  in_seq = processed_inputs[i:i + seq_length]\n",
        "  out_seq = processed_inputs[i + seq_length]\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print(\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQPERjbGLOs1",
        "outputId": "e83b2741-f370-494f-b022-a81002e26295"
      },
      "id": "dQPERjbGLOs1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 232872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conver input sequence to np array and so on\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X =X/float(vocab_len)"
      ],
      "metadata": {
        "id": "8Zs6z5PrMCA5"
      },
      "id": "8Zs6z5PrMCA5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding\n",
        "y = np.eye(np.max(y_data) + 1)[y_data]"
      ],
      "metadata": {
        "id": "C9HmhIw7MUWJ"
      },
      "id": "C9HmhIw7MUWJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "0B-Z-WHFNJFp"
      },
      "id": "0B-Z-WHFNJFp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(loss ='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "n60UQl-SP4Za"
      },
      "id": "n60UQl-SP4Za",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving weights\n",
        "filepath = 'model_weights_saved.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose = 1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "Z3e3_VLyQY_L"
      },
      "id": "Z3e3_VLyQY_L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model and let it train\n",
        "model.fit(X,y, epochs=4, batch_size=256, callbacks= desired_callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxHm9M2pQ_Yy",
        "outputId": "19b976f6-8f34-438e-c6f8-9e72201590f6"
      },
      "id": "GxHm9M2pQ_Yy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "910/910 [==============================] - ETA: 0s - loss: 2.9303\n",
            "Epoch 1: loss improved from inf to 2.93031, saving model to model_weights_saved.hdf5\n",
            "910/910 [==============================] - 3983s 4s/step - loss: 2.9303\n",
            "Epoch 2/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "910/910 [==============================] - ETA: 0s - loss: 2.9117\n",
            "Epoch 2: loss improved from 2.93031 to 2.91173, saving model to model_weights_saved.hdf5\n",
            "910/910 [==============================] - 3763s 4s/step - loss: 2.9117\n",
            "Epoch 3/4\n",
            "910/910 [==============================] - ETA: 0s - loss: 2.8980\n",
            "Epoch 3: loss improved from 2.91173 to 2.89797, saving model to model_weights_saved.hdf5\n",
            "910/910 [==============================] - 3743s 4s/step - loss: 2.8980\n",
            "Epoch 4/4\n",
            "910/910 [==============================] - ETA: 0s - loss: 2.8591\n",
            "Epoch 4: loss improved from 2.89797 to 2.85912, saving model to model_weights_saved.hdf5\n",
            "910/910 [==============================] - 3712s 4s/step - loss: 2.8591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc97a84af50>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recompile model with the saved weights\n",
        "filename = 'model_weights_saved.hdf5'\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "_18GXojJRP9f"
      },
      "id": "_18GXojJRP9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output of the model back into characters\n",
        "num_to_char = dict((i,c) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "kvyk_17ST2-Q"
      },
      "id": "kvyk_17ST2-Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# random seed to help generate\n",
        "start = np.random.randint(0, len(x_data) -1 )\n",
        "pattern = x_data[start]\n",
        "print(\"Random Send:\")\n",
        "print(\"\\\"\", \"\".join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2dwPMFEUEQK",
        "outputId": "77e49f1a-d4cd-4061-d073-4cba61fc1abd"
      },
      "id": "B2dwPMFEUEQK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Send:\n",
            "\" eredseveralmisfortunessincedepartureclervalgenevaalreadyrecoveredspiritsreportedpointmarryinglivelyp \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the text\n",
        "for i in range(1000):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = np.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in = [num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1: len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B6hQX8HUuXc",
        "outputId": "6588734a-f2ad-47ac-d4ef-13bd23506029"
      },
      "id": "8B6hQX8HUuXc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9kvKwLvWc-8"
      },
      "id": "f9kvKwLvWc-8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}